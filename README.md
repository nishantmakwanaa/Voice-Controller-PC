Description : Phoenix Makes Human Computer Interaction Simple By Making Use Of Hand Gestures And Voice Commands. The Computer Requires Almost No Direct Contact. All I/O Operations Can Be Virtually Controlled By Using Static And Dynamic Hand Gestures Along With A Voice Assistant. This Project Makes Use Of The State-Of-Art Machine Learning And Computer Vision Algorithms To Recognize Hand Gestures And Voice Commands, Which Works Smoothly Without Any Additional Hardware Requirements. It Leverages Models Such As CNN Implemented By MediaPipe Running On Top Of Pybind11. It Consists Of Two Modules: One Which Works Direct On Hands By Making Use Of MediaPipe Hand Detection, And Other Which Makes Use Of Gloves Of Any Uniform Color. Currently It Works On Windows Platform.

Gesture Control Features :

1) Neutral Gesture
2) Move Cursor
3) Left Click
4) Right Click
5) Double Click
6) Scrolling
7) Drag And Drop
8) Multiple Item Selection
9) Volume Control
10) Brightness Control

Voice Control Features :

1) Launch / Stop Gesture Controls
2) Google Search
3) Find A Location On Google Maps
4) File Navigation
5) Current Date And Time
6) Copy And Paste
7) Sleep / Wake Up Phoenix
8) Exit

Installation Process :

First Install Anaconda And Python.

1) Run Command : conda create --name assistant
2) Run Command : conda activate assistant
3) Run Command : pip install -r requirements.txt
4) Go To Project Root Folder And Run Command : python Phoenix.py